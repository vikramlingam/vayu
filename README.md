# Vayu Voice AI ğŸ¤âš¡

**Vayu** is a real-time voice AI assistant that lets you have natural conversations with an AI. Just speak, and it responds with natural-sounding voice like talking to a friend who happens to know everything.

![Demo](https://img.shields.io/badge/Status-Ready-green) ![Python](https://img.shields.io/badge/Python-3.10+-blue) ![License](https://img.shields.io/badge/License-MIT-yellow)

<p align="center">
  <img src="vayu.png" alt="Vayu Voice AI" width="300" />
</p>


---

## âœ¨ Features

- **100% Local Speech Processing** - Your voice never leaves your machine (STT + TTS run locally)
- **Natural Conversations** - Speak naturally, pause to think, and continueâ€”smart pause detection waits for you
- **Real-time Streaming** - Hear responses as they're generated, not after a long wait
- **Barge-in Support** - Interrupt the AI mid-sentence if you need to
- **Pleasant Audio Cues** - A gentle chime indicates when the AI is about to respond
- **Interactive Voice Selection** - Choose from multiple high-quality voices on startup
- **Echo Cancellation** - Novel voice fingerprinting prevents the AI from hearing itself

---

## ğŸ—ï¸ Architecture

Vayu uses an **Actor Model** with three concurrent pipelines for ultra-low latency:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VAYU ARCHITECTURE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚   MIC   â”‚â”€â”€â”€â–¶â”‚   VAD   â”‚â”€â”€â”€â–¶â”‚   STT   â”‚â”€â”€â”€â–¶â”‚  QUEUE  â”‚     â”‚
â”‚   â”‚ (Input) â”‚    â”‚(Silero) â”‚    â”‚(Whisper)â”‚    â”‚         â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â”‚
â”‚                                                      â”‚          â”‚
â”‚                      LOOP 1: Audio â†’ Text            â”‚          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                      â”‚          â”‚
â”‚                                                      â–¼          â”‚
â”‚                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                                                â”‚   LLM   â”‚      â”‚
â”‚                                                â”‚(OpenRtr)â”‚      â”‚
â”‚                                                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â”‚
â”‚                                                     â”‚           â”‚
â”‚                      LOOP 2: Text â†’ Response        â”‚           â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                     â”‚           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚           â”‚
â”‚   â”‚ SPEAKER â”‚â—€â”€â”€â”€â”‚   TTS   â”‚â—€â”€â”€â”€â”‚  QUEUE  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚   â”‚(Output) â”‚    â”‚(Kokoro) â”‚    â”‚         â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â”‚                      LOOP 3: Response â†’ Audio                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Design is Efficient

| Feature | Benefit |
|---------|---------|
| **3 Async Loops** | Each stage runs independently. LLM can generate while TTS is speaking |
| **Queue-based Communication** | Loops don't wait for each other; data flows through queues |
| **Streaming Everything** | LLM streams tokens â†’ TTS streams audio â†’ You hear words as they're generated |
| **Local STT/TTS** | No network latency for speech processing |
| **Smart VAD** | Learns your speaking pattern, waits longer when you pause and resume |

---

## ğŸ“¦ Project Structure

```
voice agent/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ config.py               # All configuration in one place
â”œâ”€â”€ setup_models.py         # Download required AI models
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ models/                 # AI models (downloaded automatically)
â”‚   â”œâ”€â”€ faster-whisper-tiny.en/
â”‚   â”œâ”€â”€ kokoro-v0_19.onnx
â”‚   â””â”€â”€ voices.npz
â””â”€â”€ src/
    â”œâ”€â”€ orchestrator.py     # Main brain - coordinates all 3 loops
    â”œâ”€â”€ interfaces.py       # Abstract interfaces (Strategy Pattern)
    â”œâ”€â”€ services/
    â”‚   â”œâ”€â”€ audio_manager.py    # Microphone, speaker, VAD
    â”‚   â”œâ”€â”€ stt_service.py      # Speech-to-Text (Whisper)
    â”‚   â”œâ”€â”€ tts_service.py      # Text-to-Speech (Kokoro)
    â”‚   â””â”€â”€ llm_service.py      # LLM via OpenRouter
    â””â”€â”€ utils/
        â”œâ”€â”€ voice_fingerprint.py  # Echo detection
        â””â”€â”€ sound_effects.py      # Chime sounds
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+** 
- **Microphone** (built-in or external)
- **OpenRouter API Key** ([Get one free](https://openrouter.ai/))

### Step 1: Clone or Download

```bash
cd ~/Desktop
git clone [<your-repo> "voice agent"](https://github.com/vikramlingam/vayu)
cd vayu
```

### Step 2: Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Download AI Models

```bash
python setup_models.py
```

This downloads:
- **Whisper Tiny.en** (~75MB) - for speech recognition
- **Kokoro ONNX** (~350MB) - for text-to-speech

### Step 5: Set Your API Key

Create a `.env` file:

```bash
echo "OPENROUTER_API_KEY=sk-or-v1-your-key-here" > .env
```

### Step 6: Run!

```bash
python main.py
```

You'll see:

```
ğŸ¤ Select a Voice:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 1. af_bella *
 2. af_sarah
 ...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Enter number (default: af_bella): 

ğŸ¤ Vayu is now listening...
   Speak naturally. Press Ctrl+C to stop.
```

**Just start talking!**

---

## ğŸ¯ How to Use

### Basic Conversation

1. **Speak** - Say anything naturally
2. **Pause** - Wait 1.5 seconds (or longer if you've been speaking a lot)
3. **Listen** - You'll hear a chime, then Vayu responds

### Smart Pause Detection

The system learns from your speaking pattern:

| Behavior | What Happens |
|----------|--------------|
| Quick command | 1.5s pause triggers response |
| Long explanation with pauses | System detects you're still thinking and waits longer |
| Pause and resume multiple times | Each resume adds +0.8s to the threshold (up to 3.5s max) |

### Example Session

```
ğŸ‘¤ You: Tell me about the solar system.

ğŸ¤– Vayu: The solar system has eight planets orbiting the sun...

ğŸ‘¤ You: What about Pluto?

ğŸ¤– Vayu: Pluto was reclassified as a dwarf planet in 2006...
```

---

## âš™ï¸ Configuration

All settings are in `config.py`:

### Voice Activity Detection

```python
VAD_MIN_SILENCE_MS = 1500   # Base pause threshold (1.5s)
VAD_MAX_SILENCE_MS = 3500   # Maximum pause threshold (3.5s)
VAD_RESUME_BONUS_MS = 800   # Extra time per pause-resume
```

### LLM Settings

```python
LLM_MODEL = "sao10k/l3-lunaris-8b"  # Change to any OpenRouter model
LLM_MAX_TOKENS = 1024
LLM_TEMPERATURE = 0.7
```

### TTS Voice

```python
TTS_VOICE = "af_bella"  # Available: af_bella, af_sarah, am_michael, etc.
TTS_SPEED = 1.0         # 0.5 = slower, 2.0 = faster
```

---

## ğŸ”§ Troubleshooting

### "No speech detected"

- Check your microphone is working
- Speak louder or move closer
- Increase `VAD_THRESHOLD` in config (default: 0.6)

### Audio sounds choppy

- Close other audio applications
- Try a different microphone

### LLM taking too long

- Switch to a faster models that has low latency
- Reduce `LLM_MAX_TOKENS`

### Error: OPENROUTER_API_KEY not found

- Make sure `.env` file exists in the project root
- Check the key format: `OPENROUTER_API_KEY=sk-or-v1-xxxxx`

---

## ğŸ§  Technical Details

### Services

| Service | Technology | Where It Runs |
|---------|------------|---------------|
| STT (Speech-to-Text) | faster-whisper tiny.en | Local (CPU) |
| TTS (Text-to-Speech) | kokoro-onnx | Local (CPU) |
| VAD (Voice Detection) | Silero VAD | Local (CPU) |
| LLM (Language Model) | OpenRouter API | Cloud |

### Echo Cancellation

Vayu uses **MFCC Voice Fingerprinting** to prevent hearing itself:

1. Before playing audio, store its spectral fingerprint
2. When microphone captures audio during playback, compare fingerprints
3. If similarity > 50%, it's echoâ€”ignore it
4. If different, it's the user speakingâ€”process it

---

## ğŸ“„ License

MIT License - Use freely, modify as needed.

---

## ğŸ™ Acknowledgments

- [faster-whisper](https://github.com/SYSTRAN/faster-whisper) - Fast Whisper implementation
- [kokoro-onnx](https://github.com/thewh1teagle/kokoro-onnx) - High-quality TTS
- [Silero VAD](https://github.com/snakers4/silero-vad) - Accurate voice detection
- [OpenRouter](https://openrouter.ai/) - Access to multiple LLMs

---
